# Recipe LLM Environment Configuration
# Copy this to .env and modify as needed

# Application mode: "minimal" or "full"
RECIPE_MODE=minimal

# Use mock model (true for testing, false for real LLM)
RECIPE_USE_MOCK=true

# Path to GGUF model file (only needed if RECIPE_USE_MOCK=false)
# RECIPE_MODEL_PATH=models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# Path to LoRA adapter (optional)
# RECIPE_LORA_ADAPTER_PATH=models/lora_adapters/recipe_lora_20240101_120000

# Data directory
RECIPE_DATA_DIR=data

# Ranking weights (should sum to 1.0)
RECIPE_WEIGHT_EXACT=0.5
RECIPE_WEIGHT_FUZZY=0.3
RECIPE_WEIGHT_SEMANTIC=0.2

# Fuzzy matching threshold (0-100)
RECIPE_FUZZY_THRESHOLD=80

# Model inference settings
RECIPE_MAX_TOKENS=512
RECIPE_TEMPERATURE=0.7

# Server settings
RECIPE_HOST=0.0.0.0
RECIPE_PORT=5000
